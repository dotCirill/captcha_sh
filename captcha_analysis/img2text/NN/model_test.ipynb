{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd01e5e62a6325ff353ea762e1a33ba4155ebd7d54bfe0208ca6cdc9a8e6494fce8",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 100, 100, 1)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 100, 100, 32)      320       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 25, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 25, 64)            102464    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 25, 256)           197632    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 25, 128)           164352    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 25, 40)            5160      \n",
      "=================================================================\n",
      "Total params: 488,424\n",
      "Trainable params: 488,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('normal_model.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = [' ', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '@', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# Mapping characters to integers\n",
    "char_to_num = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=list(characters), num_oov_indices=0, mask_token=None\n",
    ")\n",
    "\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")\n",
    "\n",
    "max_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    \n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :max_length\n",
    "    ]\n",
    "    \n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text\n",
    "\n",
    "def test(string):\n",
    "    fname = f'../generated_test/{string}.png'\n",
    "    img = tf.io.read_file(fname)\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [100, 100])\n",
    "    img = tf.transpose(img, perm=[1, 0, 2])\n",
    "    result = model.predict(np.array([img]))\n",
    "    return decode_batch_predictions(result)[0].replace('[UNK]', '*').replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "che bur asb ka@ hot nai l.* om\n"
     ]
    }
   ],
   "source": [
    "# be st us er @g ma il .c om\n",
    "\n",
    "#email = 'vla dis lav 199 9@g ma il. com'\n",
    "#email = 'dan il sem eno v@y an dex .ru'\n",
    "email = 'che bur ash ka@ hot mai l.c om'\n",
    "\n",
    "assert(len(email.split()) == 8)\n",
    "email_recognized = []\n",
    "for part in email.split():\n",
    "    email_recognized.append(test(part))\n",
    "\n",
    "print(' '.join(email_recognized))"
   ]
  }
 ]
}